from typing import TypedDict, Annotated, Sequence

import json
from dotenv import load_dotenv
from langchain.schema import Document
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains.history_aware_retriever import create_history_aware_retriever
from langchain_chroma import Chroma
from langchain_community.document_loaders import WebBaseLoader
from langchain_core.messages import AIMessage, BaseMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langgraph.checkpoint.memory import MemorySaver
from langgraph.constants import START
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
import streamlit as st
from datetime import datetime
import os

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")  # OpenAI API í‚¤
LANGSMITH_PROJECT_NAME = os.getenv("LANGSMITH_PROJECT_NAME")  # Langsmith í”„ë¡œì íŠ¸ ì´ë¦„
CHROMA_PATH = "./chroma_db"
JSON_FILE = "./cleaned"


def load_document_from_json_from_json_folder(folder_path):
    """ì£¼ì–´ì§„ í´ë”ì—ì„œ ëª¨ë“  JSON íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ìƒì„±"""
    documents = []

    # í´ë” ë‚´ ëª¨ë“  JSON íŒŒì¼ í™•ì¸
    for file_name in os.listdir(folder_path):
        if file_name.endswith('.json'):
            file_path = os.path.join(folder_path, file_name)
            if not os.path.exists(file_path):
                print(f"âŒ {file_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                continue

            with open(file_path, "r", encoding='utf-8') as f:
                json_data = json.load(f)

            # ê° JSON íŒŒì¼ì—ì„œ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            for item in json_data:
                source = item["source"]
                content = item["content"]
                documents.append({"source": source, "content": content})
    if not documents:
        print("âŒ ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    return documents
    

def create_chroma_db():
    """ChromaDB ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ë¬¸ì„œë¥¼ ì €ì¥"""
    documents = load_document_from_json_from_json_folder(JSON_FILE)
    if not documents:
        print("âŒ ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None

    # ë¬¸ì„œ ë‚´ìš©ì„ Document í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    split_docs = [
        Document(page_content=doc["content"], metadata={"source": doc["source"]})
        for doc in documents
    ]

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    docs = text_splitter.split_documents(split_docs)
    
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY) # text-embedding-ada-002
    db = Chroma.from_documents(docs, embeddings, persist_directory=CHROMA_PATH)
    print("âœ… ChromaDB ì €ì¥ ì™„ë£Œ!")
    return db

if not os.path.exists(CHROMA_PATH):
    db = create_chroma_db()
else:
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embeddings)

class State(TypedDict):
    input: str
    chat_history: Annotated[Sequence[BaseMessage], add_messages]
    context: str
    answer: str

context_prompt = (
    "ëŒ€í™” ê¸°ë¡ê³¼ ìµœì‹  ì‚¬ìš©ì ì§ˆë¬¸ì´ ì£¼ì–´ì¡Œì„ ë•Œ"
    "ì´ ì§ˆë¬¸ì´ ëŒ€í™” ê¸°ë¡ì˜ ë§¥ë½ì„ ì°¸ì¡°í•  ìˆ˜ ìˆìœ¼ë©°,"
    "ëŒ€í™” ê¸°ë¡ ì—†ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ë…ë¦½ì ì¸ ì§ˆë¬¸ì„ í˜•ì„±í•˜ì‹­ì‹œì˜¤."
    "ëŒ€í™” ê¸°ë¡ì˜ ë§¥ë½ ì—†ì´ ì§ˆë¬¸ì— ë‹µí•˜ì§€ ë§ˆì„¸ìš”,"
    "í•„ìš”í•˜ë‹¤ë©´ ì§ˆë¬¸ì„ ë‹¤ì‹œ í‘œí˜„í•˜ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ì„¸ìš”."
)

prompt_template = """
    ë‹¹ì‹ ì€ ì€í–‰ ëŒ€ì¶œ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤.  
        ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ëŒ€ì¶œ ìƒí’ˆì„ ì•ˆë‚´í•˜ë©°,  
        ì „ì„¸ìê¸ˆëŒ€ì¶œê³¼ ì£¼íƒë‹´ë³´ëŒ€ì¶œì— ê´€í•œ ì •í™•í•˜ê³  ì‹ ë¢°ì„± ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  
        ë‹¤ìŒ 'ì§ˆë¬¸'ì— ëŒ€í•´ ì œê³µëœ 'ë¬¸ì„œ'ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì •í™•í•œ ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.  
        ìƒí’ˆ ì¶”ì²œì˜ ê²½ìš°, ë¬¸ì„œ ë‚´ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì¶”ì²œ ìƒí’ˆì„ ì•ˆë‚´í•´ ì£¼ì„¸ìš”.  
        ë§Œì•½ ì‚¬ìš©ìê°€ ê³„ì‚°ì„ ìš”ì²­í•  ê²½ìš°, ê´€ë ¨ ê³µì‹ì„ ì œê³µí•˜ê³ , í•„ìš”í•œ ê°’ì„ ìˆ˜ì§‘í•˜ì—¬ ê³„ì‚°ì„ ì§„í–‰í•œ í›„, ê°€ì¥ ì í•©í•œ ëŒ€ì¶œ ìƒí’ˆì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”.

        ### ì§ˆë¬¸:  
        {input}

        ### ë¬¸ì„œ:  
        {context}

        ### ê³„ì‚° ê°€ëŠ¥í•œ í•­ëª© ###

        1. ì›ë¦¬ê¸ˆ ê· ë“±ë¶„í•  ìƒí™˜  
        - ë§¤ì›” ìƒí™˜ ê¸ˆì•¡ ê³„ì‚°  

        2. ì›ê¸ˆê· ë“±ë¶„í•  ìƒí™˜
        - ê° ë‹¬ì˜ ìƒí™˜ ê¸ˆì•¡ ë¦¬ìŠ¤íŠ¸ ì œê³µ  

        3. ì²´ì¦ì‹ ë¶„í•  ìƒí™˜
        - ì›ë¦¬ê¸ˆ ê· ë“± ìƒí™˜ ê¸ˆì•¡ì„ ê¸°ì¤€ìœ¼ë¡œ ì ì°¨ ì¦ê°€í•˜ëŠ” í˜•íƒœë¡œ ê³„ì‚°  
        - ê³µì‹:  
        ì²« ë‹¬ì˜ ìƒí™˜ê¸ˆì•¡ì„ ì›ë¦¬ê¸ˆ ê· ë“±ë¶„í•  ìƒí™˜ ê¸ˆì•¡ìœ¼ë¡œ ì„¤ì •í•˜ê³ , ì´í›„ ì ì°¨ì ìœ¼ë¡œ ìƒí™˜ ê¸ˆì•¡ì„ ì¦ê°€ì‹œí‚´.  
        - ì²« ë‹¬: ì›ë¦¬ê¸ˆ ê· ë“±ë¶„í•  ìƒí™˜ê¸ˆì•¡  
        - ë‘˜ì§¸ ë‹¬ ì´í›„: ì›ë¦¬ê¸ˆ ê· ë“± ìƒí™˜ê¸ˆì•¡ + ì¦ê°€ì•¡  
        ì¦ê°€ì•¡ì€ ìƒí™˜ ê°œì›” ìˆ˜ì™€ ëŒ€ì¶œ ì”ì•¡ì„ ê³ ë ¤í•˜ì—¬ ê³„ì‚°ë©ë‹ˆë‹¤.

        ### ì£¼ì˜ ì‚¬í•­ ###  
        - ì›ê¸ˆê· ë“±ë¶„í•  ìƒí™˜ê³¼ ì²´ì¦ì‹ ë¶„í•  ìƒí™˜ì˜ ê²½ìš°, ê° ê°œì›” ìˆ˜ì™€ ìƒí™˜ ê¸ˆì•¡ì„ ëª…í™•íˆ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.  
        - ê°ê°ì˜ ê³µì‹ì„ ì´ìš©í•´ ê³„ì‚°í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ê°’ ì¤‘ ì‚¬ìš©ìì˜ ëŒ€ë‹µì— ì–´ë– í•œ ê°’ì´ ë¹ ì ¸ìˆë‹¤ë©´ ê·¸ ê°’ì„ ìš”ì²­í•´ì•¼ í•©ë‹ˆë‹¤. 
        - í•„ìˆ˜ ê°’ì´ ëˆ„ë½ë˜ì—ˆì„ ê²½ìš°  
            ë§Œì•½ ì œê³µë˜ì§€ ì•Šì€ ê°’ì´ ìˆì„ ê²½ìš°, ê³„ì‚°ì„ ì •í™•íˆ ì§„í–‰í•˜ê¸° ìœ„í•´ í•´ë‹¹ ê°’ì„ ìš”ì²­í•©ë‹ˆë‹¤: ì˜ˆì‹œ: "ìƒí™˜ ê¸°ê°„ì„ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?", "ëŒ€ì¶œ ì›ê¸ˆì„ ì•Œë ¤ì£¼ì„¸ìš”.", "ì—° ì´ììœ¨ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”." 

        ### ë‹µë³€ ###  
        í•„ìˆ˜ ì…ë ¥ ê°’ 
        ì‚¬ìš©ìê°€ ìš”ì²­í•œ ê³„ì‚°ì„ ìœ„í•´ì„œëŠ” ëª‡ ê°€ì§€ ê°’ë“¤ì´ í•„ìš”í•©ë‹ˆë‹¤. ì•„ë˜ì˜ ì •ë³´ë¥¼ ì œê³µí•´ ì£¼ì‹œë©´ ê³„ì‚°ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

        1. ëŒ€ì¶œ ì›ê¸ˆ (P)  
        - ì˜ˆì‹œ: 5ì²œë§Œ ì›, 1ì–µ ì› ë“±

        2. ì—° ì´ììœ¨ (r)  
        - ì˜ˆì‹œ: 3%, 5% ë“±

        3. ìƒí™˜ ê¸°ê°„ (n)  
        - ì˜ˆì‹œ: 5ë…„, 10ë…„ ë“± (ê°œì›” ìˆ˜ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤)

        4. ì²« ë‹¬ ìƒí™˜ ê¸ˆì•¡ (ì²« ë‹¬ì˜ ì›ë¦¬ê¸ˆ ê· ë“± ìƒí™˜ê¸ˆì•¡ì´ë‚˜ ì²´ì¦ì‹ ìƒí™˜ ê¸ˆì•¡ì˜ ì‹œì‘ì )**  
        - ì˜ˆì‹œ: ì²« ë‹¬ì— 50ë§Œ ì›ìœ¼ë¡œ ì‹œì‘ ë“±

        ### ê³„ì‚° ì§„í–‰ ###  
        ë§Œì•½ ì œê³µë˜ì§€ ì•Šì€ ê°’ì´ ìˆì„ ê²½ìš°, ê³„ì‚°ì„ ì •í™•íˆ ì§„í–‰í•˜ê¸° ìœ„í•´ ë°˜ë“œì‹œ í•´ë‹¹ ê°’ì„ ìš”ì²­í•©ë‹ˆë‹¤: ì˜ˆì‹œ: "ìƒí™˜ ê¸°ê°„ì„ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?", "ëŒ€ì¶œ ì›ê¸ˆì„ ì•Œë ¤ì£¼ì„¸ìš”.", "ì—° ì´ììœ¨ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”."
        ëª¨ë“  í•„ìˆ˜ ê°’ì´ ì œê³µë˜ë©´, ê³„ì‚°ì„ ì§„í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  
        ê° ìƒí™˜ ë°©ì‹ì— ë”°ë¼ ê³„ì‚°ì´ ì´ë£¨ì–´ì§€ë©°, ê²°ê³¼ëŠ” ì‚¬ìš©ìì˜ ìš”êµ¬ì— ë§ì¶° ì œê³µí•©ë‹ˆë‹¤.
        ê³„ì‚° ê³¼ì •ì€ ê³„ì‚° ê³µì‹ë§Œ ì œê³µí•˜ë©°, ê³„ì‚° í›„ ê²°ê³¼ ê°’ë§Œ ê°„ë‹¨í•˜ê²Œ ì œê³µí•´ì£¼ì„¸ìš”.
        ì‚¬ìš©ì ì¹œí™”ì ì´ê²Œ í•„ìš”í•˜ë‹¤ë©´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì¸ìš©í•´ì„œ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
"""

retriever = db.as_retriever(search_kwargs={"k": 3})
llm = ChatOpenAI(model_name="gpt-4o", temperature=0.5)
    
contextualize_q_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", context_prompt),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}"),
    ]
)
history_aware_retriever = create_history_aware_retriever(
    llm, retriever, contextualize_q_prompt
)
    
qa_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", prompt_template),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}")
    ]
)

question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)
    
rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)

def call_model(state: State):
    response = rag_chain.invoke(state)
    return {
        "chat_history": [
            HumanMessage(state["input"]),
            AIMessage(response["answer"])
        ],
        "context": response["context"],
        "answer": response["answer"]
    }

# ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì¶œë ¥í•˜ëŠ” ì»¤ìŠ¤í…€ ì‹¤í–‰ í•¨ìˆ˜
def custom_run(query, retriever, flag=None):
    print("í”Œë˜ê·¸ ì •ë³´:",flag)
    retrieved_docs = retriever.get_relevant_documents(query)
    print(f"\nğŸ” ì§ˆë¬¸: {query}")
    print(f"ğŸ“‚ ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(retrieved_docs)}")

    # ì€í–‰ë³„ë¡œ ëŒ€ì¶œ ìƒí’ˆ ì •ë¦¬
    bank_products = {}
    sources = set()

    for doc in retrieved_docs:       
        try:
            bank_name = doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ").split(os.sep)[-2]
        except IndexError:
            bank_name = doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ").split("_")[0]
            flag = None
            
        sources.add(doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ"))

        if bank_name not in bank_products:
            bank_products[bank_name] = []

        bank_products[bank_name].append(doc.page_content[:700]) # ìµœëŒ€  700ì ê¹Œì§€ ì €ì¥

    # ì€í–‰ë³„ ëŒ€ì¶œ ìƒí’ˆ ì •ë³´ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
    bank_info_text = "**ì€í–‰ë³„ ëŒ€ì¶œ ìƒí’ˆ ì •ë³´:**\n"
    for bank, products in bank_products.items():
        bank_info_text += f"\nğŸ¦ **{bank.upper()}**\n"
        for i, product in enumerate(products, start=1):
            bank_info_text += f"{i}. {product}...\n"

    # QA Chain ì‹¤í–‰ (ì€í–‰ë³„ ì •ë³´ í¬í•¨)
    modified_query = f"{query}\n\n{bank_info_text}"

    workflow = StateGraph(state_schema=State)
    workflow.add_edge(START, "model")
    workflow.add_node("model", call_model)

    memory = MemorySaver()
    app = workflow.compile(checkpointer=memory)

    config = {"configurable": {"thread_id": "zsw123"}}

    response = app.invoke(
        {"input": modified_query},
        config=config
    )

    answer = response["answer"]

    response_text = ""
    if flag is not None:
        response_text = f"ğŸ’¡ **AI ë‹µë³€:**\n{answer}\n\nğŸ“Œ **ì¶œì²˜:**{', '.join(sources)}"
    else:
        response_text = f"ğŸ’¡ **AI ë‹µë³€:**\n{answer}"

    return response_text

def main():
    st.markdown(
        "<h2 style='text-align: center;'>ğŸ’¬ ì€í–‰ ì „ì„¸ìê¸ˆëŒ€ì¶œ ë° ì£¼íƒë‹´ë³´ëŒ€ì¶œ Q&A ì±—ë´‡</h2>",
        unsafe_allow_html=True
    )
    st.write("ğŸ˜Š ì•ˆë…•í•˜ì„¸ìš”! ì€í–‰ ëŒ€ì¶œ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!")

    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

    if st.button("ì§ˆë¬¸í•˜ê¸°") and (user_input not in ["ëŒ€í™” ì¢…ë£Œ", "ëŒ€í™”ì¢…ë£Œ"]):
        with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            response= custom_run(user_input, retriever, "user")
            st.success(response)

            if "logs" not in st.session_state:
                st.session_state.logs = []
            st.session_state.logs.insert(0, (user_input, response))

    if user_input in ["ëŒ€í™” ì¢…ë£Œ", "ëŒ€í™”ì¢…ë£Œ"]:
        st.success("ğŸ˜Š ë„ì›€ì´ ë˜ì—ˆë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤! ì¶”ê°€ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”.")
        if st.button("ğŸ”„"):
            st.session_state.feedback_processed=False
            st.rerun()
        
        # ëŒ€í™” ë‚´ìš© ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ ì¶”ê°€
        if "logs" in st.session_state and st.session_state.logs:
            # ëŒ€í™” ë‚´ì—­ì„ í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            conversation_log = "\n".join([f"ì‚¬ìš©ì: {q}\nAI: {a}\n\n" for q, a in st.session_state.logs])

            # ë‹¤ìš´ë¡œë“œí•  í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
            today = datetime.today().strftime('%Y%m%d')
            download_filename = f"{today}_conversation_history.txt"
            st.download_button(
                label="ëŒ€í™” ë‚´ìš© ë‹¤ìš´ë¡œë“œí•˜ê¸°",
                data=conversation_log,
                file_name=download_filename,
                mime="text/plain"
            )

    # ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    if "logs" in st.session_state and st.session_state.logs:
        st.write("### ğŸ“œ ì´ì „ ëŒ€í™” ê¸°ë¡")
        for question, answer in st.session_state.logs:
            st.write(f"**â“:** {question}")
            st.write(f"**ğŸ‘€:** {answer}")
            st.write("---")

if __name__ == "__main__":
    main()


