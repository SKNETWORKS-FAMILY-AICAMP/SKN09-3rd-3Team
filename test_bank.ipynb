{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í”Œë˜ê·¸ ì •ë³´: user\n",
      "\n",
      "ğŸ” ì§ˆë¬¸: ìš°ë¦¬ì€í–‰ì˜ ì–´ë–¤ ìƒí’ˆì´ì—ˆì£ ? ìƒí’ˆ ì´ë¦„ë„ ë§í•´ì£¼ì„¸ìš”\n",
      "ğŸ“‚ ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: 5\n",
      "ğŸ’¡ **AI ë‹µë³€:**\n",
      "ìš°ë¦¬ì€í–‰ì˜ ëŒ€ì¶œ ìƒí’ˆìœ¼ë¡œëŠ” \"ìš°ë¦¬WONì „ì„¸ëŒ€ì¶œ\"ê³¼ \"ìš°ë¦¬ìŠ¤ë§ˆíŠ¸ì „ì„¸ë¡ \"ì´ ìˆìŠµë‹ˆë‹¤. ì´ ìƒí’ˆë“¤ì€ ì „ì„¸ìê¸ˆëŒ€ì¶œì— í•´ë‹¹í•˜ë©°, ì „ì„¸ìê¸ˆ ëŒ€ì¶œì„ ê³ ë ¤í•˜ì‹œëŠ” ê³ ê°ë‹˜ê»˜ ì í•©í•œ ìƒí’ˆì…ë‹ˆë‹¤. ë” ìì„¸í•œ ë‚´ìš©ì´ë‚˜ ìƒë‹´ì´ í•„ìš”í•˜ì‹œë©´ ìš°ë¦¬ì€í–‰ ì˜ì—…ì ì´ë‚˜ ê³ ê°ì„¼í„°ì— ë¬¸ì˜í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Œ **ì¶œì²˜:**./data\\nonghyup\\ë†í˜‘ ì•„ë‚Œe ëŒ€ì¶œ.pdf, ./data\\woori\\ìš°ë¦¬ì „ì„¸ë¡ (ì„œìš¸ë³´ì¦ì¼ë°˜).pdf, ./data\\kookmin\\ì „ì„¸ìê¸ˆëŒ€ì¶œ_KBìŠ¤íƒ€ ì „ì„¸ìê¸ˆëŒ€ì¶œ(HF_í•œêµ­ì£¼íƒê¸ˆìœµê³µì‚¬).pdf, ./data\\woori\\ìš°ë¦¬ì „ì„¸ë¡ (ì„œìš¸ë³´ì¦-ê³µê³µì£¼íƒ).pdf, ./data\\woori\\ìš°ë¦¬WONì „ì„¸ëŒ€ì¶œ(ì£¼íƒë³´ì¦).pdf\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.constants import START\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")  # OpenAI API í‚¤\n",
    "LANGSMITH_PROJECT_NAME = os.getenv(\"LANGSMITH_PROJECT_NAME\")  # Langsmith í”„ë¡œì íŠ¸ ì´ë¦„\n",
    "CHROMA_PATH = \"./chroma_db\"\n",
    "JSON_FILE = \"./cleaned\"\n",
    "\n",
    "\n",
    "def load_document_from_json_from_json_folder(folder_path):\n",
    "    \"\"\"ì£¼ì–´ì§„ í´ë”ì—ì„œ ëª¨ë“  JSON íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ìƒì„±\"\"\"\n",
    "    documents = []\n",
    "\n",
    "    # í´ë” ë‚´ ëª¨ë“  JSON íŒŒì¼ í™•ì¸\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.json'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"âŒ {file_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤\")\n",
    "                continue\n",
    "\n",
    "            with open(file_path, \"r\", encoding='utf-8') as f:\n",
    "                json_data = json.load(f)\n",
    "\n",
    "            # ê° JSON íŒŒì¼ì—ì„œ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "            for item in json_data:\n",
    "                source = item[\"source\"]\n",
    "                content = item[\"content\"]\n",
    "                documents.append({\"source\": source, \"content\": content})\n",
    "    if not documents:\n",
    "        print(\"âŒ ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    return documents\n",
    "    \n",
    "\n",
    "def create_chroma_db():\n",
    "    \"\"\"ChromaDB ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ë¬¸ì„œë¥¼ ì €ì¥\"\"\"\n",
    "    documents = load_document_from_json_from_json_folder(JSON_FILE)\n",
    "    if not documents:\n",
    "        print(\"âŒ ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "\n",
    "    # ë¬¸ì„œ ë‚´ìš©ì„ Document í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "    split_docs = [\n",
    "        Document(page_content=doc[\"content\"], metadata={\"source\": doc[\"source\"]})\n",
    "        for doc in documents\n",
    "    ]\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    docs = text_splitter.split_documents(split_docs)\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY) # text-embedding-ada-002\n",
    "    db = Chroma.from_documents(docs, embeddings, persist_directory=CHROMA_PATH)\n",
    "    print(\"âœ… ChromaDB ì €ì¥ ì™„ë£Œ!\")\n",
    "    return db\n",
    "\n",
    "if not os.path.exists(CHROMA_PATH):\n",
    "    db = create_chroma_db()\n",
    "else:\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embeddings)\n",
    "\n",
    "class State(TypedDict):\n",
    "    input: str\n",
    "    chat_history: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    context: str\n",
    "    answer: str\n",
    "\n",
    "context_prompt = (\n",
    "    \"ì£¼ì–´ì§„ ëŒ€í™” ê¸°ë¡ê³¼ ì‚¬ìš©ìì˜ ìµœì‹  ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”.\"\n",
    "    \"1. ìµœì‹  ì§ˆë¬¸ì´ ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì— ì˜ì¡´í•˜ëŠ”ì§€ íŒë‹¨í•©ë‹ˆë‹¤.\"\n",
    "    \"2. ë§¥ë½ì— ì˜ì¡´í•˜ëŠ” ê²½ìš°, ì´ì „ ëŒ€í™”ë¥¼ ì°¸ê³ í•˜ì—¬ ì™„ì „í•˜ê³  ë…ë¦½ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.\"\n",
    "    \"3. ë§¥ë½ ì—†ì´ë„ ì´í•´ ê°€ëŠ¥í•œ ì§ˆë¬¸ì´ë¼ë©´, ì›ë˜ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.\"\n",
    "    \"4. ì´ì „ ëŒ€í™” ê¸°ë¡ ì—†ì´ëŠ” ë‹µë³€í•  ìˆ˜ ì—†ëŠ” ì§ˆë¬¸ì€ ì²˜ë¦¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\"\n",
    ")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "    ë‹¹ì‹ ì€ ì€í–‰ ëŒ€ì¶œ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤.  \n",
    "        ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ëŒ€ì¶œ ìƒí’ˆì„ ì•ˆë‚´í•˜ë©°,  \n",
    "        ì „ì„¸ìê¸ˆëŒ€ì¶œê³¼ ì£¼íƒë‹´ë³´ëŒ€ì¶œì— ê´€í•œ ì •í™•í•˜ê³  ì‹ ë¢°ì„± ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  \n",
    "        ë‹¤ìŒ 'ì§ˆë¬¸'ì— ëŒ€í•´ ì œê³µëœ 'ë¬¸ì„œ'ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì •í™•í•œ ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.  \n",
    "        ìƒí’ˆ ì¶”ì²œì˜ ê²½ìš°, ë¬¸ì„œ ë‚´ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì¶”ì²œ ìƒí’ˆì„ ì•ˆë‚´í•´ ì£¼ì„¸ìš”.  \n",
    "        ë§Œì•½ ì‚¬ìš©ìê°€ ê³„ì‚°ì„ ìš”ì²­í•  ê²½ìš°, ê´€ë ¨ ê³µì‹ì„ ì œê³µí•˜ê³ , í•„ìš”í•œ ê°’ì„ ìˆ˜ì§‘í•˜ì—¬ ê³„ì‚°ì„ ì§„í–‰í•œ í›„, ê°€ì¥ ì í•©í•œ ëŒ€ì¶œ ìƒí’ˆì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "        ### ì§ˆë¬¸:  \n",
    "        {input}\n",
    "\n",
    "        ### ë¬¸ì„œ:  \n",
    "        {context}\n",
    "\n",
    "        ### ê³„ì‚° ê°€ëŠ¥í•œ í•­ëª© ###\n",
    "\n",
    "        1. ì›ë¦¬ê¸ˆ ê· ë“±ë¶„í•  ìƒí™˜  \n",
    "        - ë§¤ì›” ìƒí™˜ ê¸ˆì•¡ ê³„ì‚°  \n",
    "\n",
    "        2. ì›ê¸ˆê· ë“±ë¶„í•  ìƒí™˜\n",
    "        - ê° ë‹¬ì˜ ìƒí™˜ ê¸ˆì•¡ ë¦¬ìŠ¤íŠ¸ ì œê³µ  \n",
    "\n",
    "        3. ì²´ì¦ì‹ ë¶„í•  ìƒí™˜\n",
    "        - ì›ë¦¬ê¸ˆ ê· ë“± ìƒí™˜ ê¸ˆì•¡ì„ ê¸°ì¤€ìœ¼ë¡œ ì ì°¨ ì¦ê°€í•˜ëŠ” í˜•íƒœë¡œ ê³„ì‚°  \n",
    "        - ê³µì‹:  \n",
    "        ì²« ë‹¬ì˜ ìƒí™˜ê¸ˆì•¡ì„ ì›ë¦¬ê¸ˆ ê· ë“±ë¶„í•  ìƒí™˜ ê¸ˆì•¡ìœ¼ë¡œ ì„¤ì •í•˜ê³ , ì´í›„ ì ì°¨ì ìœ¼ë¡œ ìƒí™˜ ê¸ˆì•¡ì„ ì¦ê°€ì‹œí‚´.  \n",
    "        - ì²« ë‹¬: ì›ë¦¬ê¸ˆ ê· ë“±ë¶„í•  ìƒí™˜ê¸ˆì•¡  \n",
    "        - ë‘˜ì§¸ ë‹¬ ì´í›„: ì›ë¦¬ê¸ˆ ê· ë“± ìƒí™˜ê¸ˆì•¡ + ì¦ê°€ì•¡  \n",
    "        ì¦ê°€ì•¡ì€ ìƒí™˜ ê°œì›” ìˆ˜ì™€ ëŒ€ì¶œ ì”ì•¡ì„ ê³ ë ¤í•˜ì—¬ ê³„ì‚°ë©ë‹ˆë‹¤.\n",
    "\n",
    "        ### ì£¼ì˜ ì‚¬í•­ ###  \n",
    "        - ì›ê¸ˆê· ë“±ë¶„í•  ìƒí™˜ê³¼ ì²´ì¦ì‹ ë¶„í•  ìƒí™˜ì˜ ê²½ìš°, ê° ê°œì›” ìˆ˜ì™€ ìƒí™˜ ê¸ˆì•¡ì„ ëª…í™•íˆ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.  \n",
    "        - ê°ê°ì˜ ê³µì‹ì„ ì´ìš©í•´ ê³„ì‚°í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ê°’ ì¤‘ ì‚¬ìš©ìì˜ ëŒ€ë‹µì— ì–´ë– í•œ ê°’ì´ ë¹ ì ¸ìˆë‹¤ë©´ ê·¸ ê°’ì„ ìš”ì²­í•´ì•¼ í•©ë‹ˆë‹¤. \n",
    "        - í•„ìˆ˜ ê°’ì´ ëˆ„ë½ë˜ì—ˆì„ ê²½ìš°  \n",
    "            ë§Œì•½ ì œê³µë˜ì§€ ì•Šì€ ê°’ì´ ìˆì„ ê²½ìš°, ê³„ì‚°ì„ ì •í™•íˆ ì§„í–‰í•˜ê¸° ìœ„í•´ í•´ë‹¹ ê°’ì„ ìš”ì²­í•©ë‹ˆë‹¤: ì˜ˆì‹œ: \"ìƒí™˜ ê¸°ê°„ì„ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?\", \"ëŒ€ì¶œ ì›ê¸ˆì„ ì•Œë ¤ì£¼ì„¸ìš”.\", \"ì—° ì´ììœ¨ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\" \n",
    "\n",
    "        ### ë‹µë³€ ###  \n",
    "        í•„ìˆ˜ ì…ë ¥ ê°’ \n",
    "        ì‚¬ìš©ìê°€ ìš”ì²­í•œ ê³„ì‚°ì„ ìœ„í•´ì„œëŠ” ëª‡ ê°€ì§€ ê°’ë“¤ì´ í•„ìš”í•©ë‹ˆë‹¤. ì•„ë˜ì˜ ì •ë³´ë¥¼ ì œê³µí•´ ì£¼ì‹œë©´ ê³„ì‚°ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "        1. ëŒ€ì¶œ ì›ê¸ˆ (P)  \n",
    "        - ì˜ˆì‹œ: 5ì²œë§Œ ì›, 1ì–µ ì› ë“±\n",
    "\n",
    "        2. ì—° ì´ììœ¨ (r)  \n",
    "        - ì˜ˆì‹œ: 3%, 5% ë“±\n",
    "\n",
    "        3. ìƒí™˜ ê¸°ê°„ (n)  \n",
    "        - ì˜ˆì‹œ: 5ë…„, 10ë…„ ë“± (ê°œì›” ìˆ˜ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤)\n",
    "\n",
    "        4. ì²« ë‹¬ ìƒí™˜ ê¸ˆì•¡ (ì²« ë‹¬ì˜ ì›ë¦¬ê¸ˆ ê· ë“± ìƒí™˜ê¸ˆì•¡ì´ë‚˜ ì²´ì¦ì‹ ìƒí™˜ ê¸ˆì•¡ì˜ ì‹œì‘ì )**  \n",
    "        - ì˜ˆì‹œ: ì²« ë‹¬ì— 50ë§Œ ì›ìœ¼ë¡œ ì‹œì‘ ë“±\n",
    "\n",
    "        ### ê³„ì‚° ì§„í–‰ ###  \n",
    "        ë§Œì•½ ì œê³µë˜ì§€ ì•Šì€ ê°’ì´ ìˆì„ ê²½ìš°, ê³„ì‚°ì„ ì •í™•íˆ ì§„í–‰í•˜ê¸° ìœ„í•´ ë°˜ë“œì‹œ í•´ë‹¹ ê°’ì„ ìš”ì²­í•©ë‹ˆë‹¤: ì˜ˆì‹œ: \"ìƒí™˜ ê¸°ê°„ì„ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?\", \"ëŒ€ì¶œ ì›ê¸ˆì„ ì•Œë ¤ì£¼ì„¸ìš”.\", \"ì—° ì´ììœ¨ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\"\n",
    "        ëª¨ë“  í•„ìˆ˜ ê°’ì´ ì œê³µë˜ë©´, ê³„ì‚°ì„ ì§„í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  \n",
    "        ê° ìƒí™˜ ë°©ì‹ì— ë”°ë¼ ê³„ì‚°ì´ ì´ë£¨ì–´ì§€ë©°, ê²°ê³¼ëŠ” ì‚¬ìš©ìì˜ ìš”êµ¬ì— ë§ì¶° ì œê³µí•©ë‹ˆë‹¤.\n",
    "        ê³„ì‚° ê³¼ì •ì€ ê³„ì‚° ê³µì‹ë§Œ ì œê³µí•˜ë©°, ê³„ì‚° í›„ ê²°ê³¼ ê°’ë§Œ ê°„ë‹¨í•˜ê²Œ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "        ì‚¬ìš©ì ì¹œí™”ì ì´ê²Œ í•„ìš”í•˜ë‹¤ë©´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì¸ìš©í•´ì„œ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.3)\n",
    "    \n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", context_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "    \n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", prompt_template),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "    \n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "def call_model(state: State):\n",
    "    response = rag_chain.invoke(state)\n",
    "\n",
    "    updated_chat_history = state[\"chat_history\"] + [\n",
    "        HumanMessage(state[\"input\"]),\n",
    "        AIMessage(response[\"answer\"])\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"chat_history\": updated_chat_history,\n",
    "        \"context\": response[\"context\"],\n",
    "        \"answer\": response[\"answer\"]\n",
    "    }\n",
    "\n",
    "# ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì¶œë ¥í•˜ëŠ” ì»¤ìŠ¤í…€ ì‹¤í–‰ í•¨ìˆ˜\n",
    "def custom_run(query, retriever, flag=None):\n",
    "    print(\"í”Œë˜ê·¸ ì •ë³´:\",flag)\n",
    "    retrieved_docs = retriever.get_relevant_documents(query)\n",
    "    print(f\"\\nğŸ” ì§ˆë¬¸: {query}\")\n",
    "    print(f\"ğŸ“‚ ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(retrieved_docs)}\")\n",
    "\n",
    "    # ì€í–‰ë³„ë¡œ ëŒ€ì¶œ ìƒí’ˆ ì •ë¦¬\n",
    "    bank_products = {}\n",
    "    sources = set()\n",
    "\n",
    "    for doc in retrieved_docs:       \n",
    "        try:\n",
    "            bank_name = doc.metadata.get(\"source\", \"ì•Œ ìˆ˜ ì—†ìŒ\").split(os.sep)[-2]\n",
    "        except IndexError:\n",
    "            bank_name = doc.metadata.get(\"source\", \"ì•Œ ìˆ˜ ì—†ìŒ\").split(\"_\")[0]\n",
    "            flag = None\n",
    "            \n",
    "        sources.add(doc.metadata.get(\"source\", \"ì•Œ ìˆ˜ ì—†ìŒ\"))\n",
    "\n",
    "        if bank_name not in bank_products:\n",
    "            bank_products[bank_name] = []\n",
    "\n",
    "        bank_products[bank_name].append(doc.page_content[:700]) # ìµœëŒ€  700ì ê¹Œì§€ ì €ì¥\n",
    "\n",
    "    # ì€í–‰ë³„ ëŒ€ì¶œ ìƒí’ˆ ì •ë³´ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±\n",
    "    bank_info_text = \"**ì€í–‰ë³„ ëŒ€ì¶œ ìƒí’ˆ ì •ë³´:**\\n\"\n",
    "    for bank, products in bank_products.items():\n",
    "        bank_info_text += f\"\\nğŸ¦ **{bank.upper()}**\\n\"\n",
    "        for i, product in enumerate(products, start=1):\n",
    "            bank_info_text += f\"{i}. {product}...\\n\"\n",
    "\n",
    "    # QA Chain ì‹¤í–‰ (ì€í–‰ë³„ ì •ë³´ í¬í•¨)\n",
    "    modified_query = f\"{query}\\n\\n{bank_info_text}\"\n",
    "\n",
    "    workflow = StateGraph(state_schema=State)\n",
    "    workflow.add_edge(START, \"model\")\n",
    "    workflow.add_node(\"model\", call_model)\n",
    "\n",
    "    memory = MemorySaver()\n",
    "    app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": \"zsw123\"}}\n",
    "\n",
    "    response = app.invoke(\n",
    "        {\"input\": modified_query},\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "    answer = response[\"answer\"]\n",
    "\n",
    "    response_text = \"\"\n",
    "    if flag is not None:\n",
    "        response_text = f\"ğŸ’¡ **AI ë‹µë³€:**\\n{answer}\\n\\nğŸ“Œ **ì¶œì²˜:**{', '.join(sources)}\"\n",
    "    else:\n",
    "        response_text = f\"ğŸ’¡ **AI ë‹µë³€:**\\n{answer}\"\n",
    "\n",
    "    return response_text\n",
    "\n",
    "user_input = str(input(\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.\"))\n",
    "response = custom_run(user_input, retriever, \"user\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3nd_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
