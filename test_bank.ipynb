{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "플래그 정보: user\n",
      "\n",
      "🔎 질문: 우리은행의 어떤 상품이었죠? 상품 이름도 말해주세요\n",
      "📂 검색된 문서 개수: 5\n",
      "💡 **AI 답변:**\n",
      "우리은행의 대출 상품으로는 \"우리WON전세대출\"과 \"우리스마트전세론\"이 있습니다. 이 상품들은 전세자금대출에 해당하며, 전세자금 대출을 고려하시는 고객님께 적합한 상품입니다. 더 자세한 내용이나 상담이 필요하시면 우리은행 영업점이나 고객센터에 문의하실 수 있습니다.\n",
      "\n",
      "📌 **출처:**./data\\nonghyup\\농협 아낌e 대출.pdf, ./data\\woori\\우리전세론(서울보증일반).pdf, ./data\\kookmin\\전세자금대출_KB스타 전세자금대출(HF_한국주택금융공사).pdf, ./data\\woori\\우리전세론(서울보증-공공주택).pdf, ./data\\woori\\우리WON전세대출(주택보증).pdf\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.constants import START\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")  # OpenAI API 키\n",
    "LANGSMITH_PROJECT_NAME = os.getenv(\"LANGSMITH_PROJECT_NAME\")  # Langsmith 프로젝트 이름\n",
    "CHROMA_PATH = \"./chroma_db\"\n",
    "JSON_FILE = \"./cleaned\"\n",
    "\n",
    "\n",
    "def load_document_from_json_from_json_folder(folder_path):\n",
    "    \"\"\"주어진 폴더에서 모든 JSON 파일을 로드하여 문서 리스트 생성\"\"\"\n",
    "    documents = []\n",
    "\n",
    "    # 폴더 내 모든 JSON 파일 확인\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.json'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"❌ {file_path} 파일이 존재하지 않습니다\")\n",
    "                continue\n",
    "\n",
    "            with open(file_path, \"r\", encoding='utf-8') as f:\n",
    "                json_data = json.load(f)\n",
    "\n",
    "            # 각 JSON 파일에서 문서 리스트로 변환\n",
    "            for item in json_data:\n",
    "                source = item[\"source\"]\n",
    "                content = item[\"content\"]\n",
    "                documents.append({\"source\": source, \"content\": content})\n",
    "    if not documents:\n",
    "        print(\"❌ 문서가 존재하지 않습니다.\")\n",
    "\n",
    "    return documents\n",
    "    \n",
    "\n",
    "def create_chroma_db():\n",
    "    \"\"\"ChromaDB 인덱스를 생성하고 문서를 저장\"\"\"\n",
    "    documents = load_document_from_json_from_json_folder(JSON_FILE)\n",
    "    if not documents:\n",
    "        print(\"❌ 문서가 존재하지 않습니다.\")\n",
    "        return None\n",
    "\n",
    "    # 문서 내용을 Document 형식으로 변환\n",
    "    split_docs = [\n",
    "        Document(page_content=doc[\"content\"], metadata={\"source\": doc[\"source\"]})\n",
    "        for doc in documents\n",
    "    ]\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    docs = text_splitter.split_documents(split_docs)\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY) # text-embedding-ada-002\n",
    "    db = Chroma.from_documents(docs, embeddings, persist_directory=CHROMA_PATH)\n",
    "    print(\"✅ ChromaDB 저장 완료!\")\n",
    "    return db\n",
    "\n",
    "if not os.path.exists(CHROMA_PATH):\n",
    "    db = create_chroma_db()\n",
    "else:\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embeddings)\n",
    "\n",
    "class State(TypedDict):\n",
    "    input: str\n",
    "    chat_history: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    context: str\n",
    "    answer: str\n",
    "\n",
    "context_prompt = (\n",
    "    \"주어진 대화 기록과 사용자의 최신 질문을 분석하여 다음을 수행하세요.\"\n",
    "    \"1. 최신 질문이 이전 대화의 맥락에 의존하는지 판단합니다.\"\n",
    "    \"2. 맥락에 의존하는 경우, 이전 대화를 참고하여 완전하고 독립적인 질문으로 재구성합니다.\"\n",
    "    \"3. 맥락 없이도 이해 가능한 질문이라면, 원래 질문을 그대로 유지합니다.\"\n",
    "    \"4. 이전 대화 기록 없이는 답변할 수 없는 질문은 처리하지 않습니다.\"\n",
    ")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "    당신은 은행 대출 전문가 AI입니다.  \n",
    "        사용자에게 친절하고 상세하게 대출 상품을 안내하며,  \n",
    "        전세자금대출과 주택담보대출에 관한 정확하고 신뢰성 있는 정보를 제공합니다.  \n",
    "        다음 '질문'에 대해 제공된 '문서'의 내용을 바탕으로 구체적이고 정확한 답변을 작성해 주세요.  \n",
    "        상품 추천의 경우, 문서 내용을 중심으로 추천 상품을 안내해 주세요.  \n",
    "        만약 사용자가 계산을 요청할 경우, 관련 공식을 제공하고, 필요한 값을 수집하여 계산을 진행한 후, 가장 적합한 대출 상품을 추천해 주세요.\n",
    "\n",
    "        ### 질문:  \n",
    "        {input}\n",
    "\n",
    "        ### 문서:  \n",
    "        {context}\n",
    "\n",
    "        ### 계산 가능한 항목 ###\n",
    "\n",
    "        1. 원리금 균등분할 상환  \n",
    "        - 매월 상환 금액 계산  \n",
    "\n",
    "        2. 원금균등분할 상환\n",
    "        - 각 달의 상환 금액 리스트 제공  \n",
    "\n",
    "        3. 체증식 분할 상환\n",
    "        - 원리금 균등 상환 금액을 기준으로 점차 증가하는 형태로 계산  \n",
    "        - 공식:  \n",
    "        첫 달의 상환금액을 원리금 균등분할 상환 금액으로 설정하고, 이후 점차적으로 상환 금액을 증가시킴.  \n",
    "        - 첫 달: 원리금 균등분할 상환금액  \n",
    "        - 둘째 달 이후: 원리금 균등 상환금액 + 증가액  \n",
    "        증가액은 상환 개월 수와 대출 잔액을 고려하여 계산됩니다.\n",
    "\n",
    "        ### 주의 사항 ###  \n",
    "        - 원금균등분할 상환과 체증식 분할 상환의 경우, 각 개월 수와 상환 금액을 명확히 제공해야 합니다.  \n",
    "        - 각각의 공식을 이용해 계산하기 위해 필요한 값 중 사용자의 대답에 어떠한 값이 빠져있다면 그 값을 요청해야 합니다. \n",
    "        - 필수 값이 누락되었을 경우  \n",
    "            만약 제공되지 않은 값이 있을 경우, 계산을 정확히 진행하기 위해 해당 값을 요청합니다: 예시: \"상환 기간을 알려주시겠어요?\", \"대출 원금을 알려주세요.\", \"연 이자율을 입력해 주세요.\" \n",
    "\n",
    "        ### 답변 ###  \n",
    "        필수 입력 값 \n",
    "        사용자가 요청한 계산을 위해서는 몇 가지 값들이 필요합니다. 아래의 정보를 제공해 주시면 계산을 진행할 수 있습니다:\n",
    "\n",
    "        1. 대출 원금 (P)  \n",
    "        - 예시: 5천만 원, 1억 원 등\n",
    "\n",
    "        2. 연 이자율 (r)  \n",
    "        - 예시: 3%, 5% 등\n",
    "\n",
    "        3. 상환 기간 (n)  \n",
    "        - 예시: 5년, 10년 등 (개월 수로 계산됩니다)\n",
    "\n",
    "        4. 첫 달 상환 금액 (첫 달의 원리금 균등 상환금액이나 체증식 상환 금액의 시작점)**  \n",
    "        - 예시: 첫 달에 50만 원으로 시작 등\n",
    "\n",
    "        ### 계산 진행 ###  \n",
    "        만약 제공되지 않은 값이 있을 경우, 계산을 정확히 진행하기 위해 반드시 해당 값을 요청합니다: 예시: \"상환 기간을 알려주시겠어요?\", \"대출 원금을 알려주세요.\", \"연 이자율을 입력해 주세요.\"\n",
    "        모든 필수 값이 제공되면, 계산을 진행하여 결과를 제공합니다.  \n",
    "        각 상환 방식에 따라 계산이 이루어지며, 결과는 사용자의 요구에 맞춰 제공합니다.\n",
    "        계산 과정은 계산 공식만 제공하며, 계산 후 결과 값만 간단하게 제공해주세요.\n",
    "        사용자 친화적이게 필요하다면 사용자의 질문을 인용해서 답변을 생성해주세요.\n",
    "\"\"\"\n",
    "\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.3)\n",
    "    \n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", context_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "    \n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", prompt_template),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "    \n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "def call_model(state: State):\n",
    "    response = rag_chain.invoke(state)\n",
    "\n",
    "    updated_chat_history = state[\"chat_history\"] + [\n",
    "        HumanMessage(state[\"input\"]),\n",
    "        AIMessage(response[\"answer\"])\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"chat_history\": updated_chat_history,\n",
    "        \"context\": response[\"context\"],\n",
    "        \"answer\": response[\"answer\"]\n",
    "    }\n",
    "\n",
    "# 검색된 문서를 출력하는 커스텀 실행 함수\n",
    "def custom_run(query, retriever, flag=None):\n",
    "    print(\"플래그 정보:\",flag)\n",
    "    retrieved_docs = retriever.get_relevant_documents(query)\n",
    "    print(f\"\\n🔎 질문: {query}\")\n",
    "    print(f\"📂 검색된 문서 개수: {len(retrieved_docs)}\")\n",
    "\n",
    "    # 은행별로 대출 상품 정리\n",
    "    bank_products = {}\n",
    "    sources = set()\n",
    "\n",
    "    for doc in retrieved_docs:       \n",
    "        try:\n",
    "            bank_name = doc.metadata.get(\"source\", \"알 수 없음\").split(os.sep)[-2]\n",
    "        except IndexError:\n",
    "            bank_name = doc.metadata.get(\"source\", \"알 수 없음\").split(\"_\")[0]\n",
    "            flag = None\n",
    "            \n",
    "        sources.add(doc.metadata.get(\"source\", \"알 수 없음\"))\n",
    "\n",
    "        if bank_name not in bank_products:\n",
    "            bank_products[bank_name] = []\n",
    "\n",
    "        bank_products[bank_name].append(doc.page_content[:700]) # 최대  700자 까지 저장\n",
    "\n",
    "    # 은행별 대출 상품 정보를 하나의 텍스트로 구성\n",
    "    bank_info_text = \"**은행별 대출 상품 정보:**\\n\"\n",
    "    for bank, products in bank_products.items():\n",
    "        bank_info_text += f\"\\n🏦 **{bank.upper()}**\\n\"\n",
    "        for i, product in enumerate(products, start=1):\n",
    "            bank_info_text += f\"{i}. {product}...\\n\"\n",
    "\n",
    "    # QA Chain 실행 (은행별 정보 포함)\n",
    "    modified_query = f\"{query}\\n\\n{bank_info_text}\"\n",
    "\n",
    "    workflow = StateGraph(state_schema=State)\n",
    "    workflow.add_edge(START, \"model\")\n",
    "    workflow.add_node(\"model\", call_model)\n",
    "\n",
    "    memory = MemorySaver()\n",
    "    app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": \"zsw123\"}}\n",
    "\n",
    "    response = app.invoke(\n",
    "        {\"input\": modified_query},\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "    answer = response[\"answer\"]\n",
    "\n",
    "    response_text = \"\"\n",
    "    if flag is not None:\n",
    "        response_text = f\"💡 **AI 답변:**\\n{answer}\\n\\n📌 **출처:**{', '.join(sources)}\"\n",
    "    else:\n",
    "        response_text = f\"💡 **AI 답변:**\\n{answer}\"\n",
    "\n",
    "    return response_text\n",
    "\n",
    "user_input = str(input(\"질문을 입력하세요.\"))\n",
    "response = custom_run(user_input, retriever, \"user\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3nd_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
