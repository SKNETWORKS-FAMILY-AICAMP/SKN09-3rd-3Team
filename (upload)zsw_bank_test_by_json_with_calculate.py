import os
import json
import streamlit as st
from langchain.chains import RetrievalQA
from langchain.schema import Document
from langchain.memory import ConversationBufferMemory
from langchain_openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains.question_answering import load_qa_chain
from langchain_chroma import Chroma
from langchain.text_splitter import CharacterTextSplitter
from langchain.document_loaders import PyPDFLoader
from langchain.prompts import PromptTemplate
from datetime import datetime


# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
OPENAI_API_KEY = "[API KEY ì…ë ¥]"
CHROMA_PATH = "./chroma_db"
JSON_FILE = "./cleaned"

# .json ì¶”ì¶œ ë° í†µí•©í•©
def load_document_from_json_from_json_folder(folder_path):
    documents = []

    for file_name in os.listdir(folder_path):
        if file_name.endswith('.json'):
            file_path = os.path.join(folder_path, file_name)
            if not os.path.exists(file_path):
                print(f"âŒ {file_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                continue

            with open(file_path, "r", encoding='utf-8') as f:
                json_data = json.load(f)

            for item in json_data:
                source = item["source"]
                content = item["content"]
                documents.append({"source": source, "content": content})
    if not documents:
        print("âŒ ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    return documents
    

def create_chroma_db():
    documents = load_document_from_json_from_json_folder(JSON_FILE)
    if not documents:
        print("âŒ ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None

    split_docs = [
        Document(page_content=doc["content"], metadata={"source": doc["source"]})
        for doc in documents
    ]

    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    docs = text_splitter.split_documents(split_docs)
    
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY) # text-embedding-ada-002
    db = Chroma.from_documents(docs, embeddings, persist_directory=CHROMA_PATH)
    print("âœ… ChromaDB ì €ì¥ ì™„ë£Œ!")
    return db

def get_qa_chain_with_memory(db, flag=None):
    flag_var = flag

    retriever = db.as_retriever(search_kwargs={"k": 10})
    llm = ChatOpenAI(model_name="gpt-4o", openai_api_key=OPENAI_API_KEY, temperature=0.5)

    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    custom_prompt = PromptTemplate(
        input_variables=["context", "question"], 
        template=(
            """
                ë‹¹ì‹ ì€ ì€í–‰ ëŒ€ì¶œ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤.  
                ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ëŒ€ì¶œ ìƒí’ˆì„ ì•ˆë‚´í•˜ë©°,  
                ì „ì„¸ìê¸ˆëŒ€ì¶œê³¼ ì£¼íƒë‹´ë³´ëŒ€ì¶œì— ê´€í•œ ì •í™•í•˜ê³  ì‹ ë¢°ì„± ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  
                ë‹¤ìŒ 'ì§ˆë¬¸'ì— ëŒ€í•´ ì œê³µëœ 'ë¬¸ì„œ'ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì •í™•í•œ ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.  
                ìƒí’ˆ ì¶”ì²œì˜ ê²½ìš°, ë¬¸ì„œ ë‚´ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì¶”ì²œ ìƒí’ˆì„ ì•ˆë‚´í•´ ì£¼ì„¸ìš”.  
                ë§Œì•½ ì‚¬ìš©ìê°€ ê³„ì‚°ì„ ìš”ì²­í•  ê²½ìš°, ê´€ë ¨ ê³µì‹ì„ ì œê³µí•˜ê³ , í•„ìš”í•œ ê°’ì„ ìˆ˜ì§‘í•˜ì—¬ ê³„ì‚°ì„ ì§„í–‰í•œ í›„, ê°€ì¥ ì í•©í•œ ëŒ€ì¶œ ìƒí’ˆì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”.

                ### ì§ˆë¬¸:  
                {question}

                ### ë¬¸ì„œ:  
                {context}

                ### ê³„ì‚° ê°€ëŠ¥í•œ í•­ëª© ###

                1. ì›ë¦¬ê¸ˆ ê· ë“±ë¶„í•  ìƒí™˜  
                - ë§¤ì›” ìƒí™˜ ê¸ˆì•¡ ê³„ì‚°  

                2. ì›ê¸ˆê· ë“±ë¶„í•  ìƒí™˜
                - ê° ë‹¬ì˜ ìƒí™˜ ê¸ˆì•¡ ë¦¬ìŠ¤íŠ¸ ì œê³µ  

                3. ì²´ì¦ì‹ ë¶„í•  ìƒí™˜
                - ì›ë¦¬ê¸ˆ ê· ë“± ìƒí™˜ ê¸ˆì•¡ì„ ê¸°ì¤€ìœ¼ë¡œ ì ì°¨ ì¦ê°€í•˜ëŠ” í˜•íƒœë¡œ ê³„ì‚°  
                - ê³µì‹:  
                    ì²« ë‹¬ì˜ ìƒí™˜ê¸ˆì•¡ì„ ì›ë¦¬ê¸ˆ ê· ë“±ë¶„í•  ìƒí™˜ ê¸ˆì•¡ìœ¼ë¡œ ì„¤ì •í•˜ê³ , ì´í›„ ì ì°¨ì ìœ¼ë¡œ ìƒí™˜ ê¸ˆì•¡ì„ ì¦ê°€ì‹œí‚´.  
                    - ì²« ë‹¬: ì›ë¦¬ê¸ˆ ê· ë“±ë¶„í•  ìƒí™˜ê¸ˆì•¡  
                    - ë‘˜ì§¸ ë‹¬ ì´í›„: ì›ë¦¬ê¸ˆ ê· ë“± ìƒí™˜ê¸ˆì•¡ + ì¦ê°€ì•¡  
                    ì¦ê°€ì•¡ì€ ìƒí™˜ ê°œì›” ìˆ˜ì™€ ëŒ€ì¶œ ì”ì•¡ì„ ê³ ë ¤í•˜ì—¬ ê³„ì‚°ë©ë‹ˆë‹¤.

                ### ì£¼ì˜ ì‚¬í•­ ###  
                - ì›ê¸ˆê· ë“±ë¶„í•  ìƒí™˜ê³¼ ì²´ì¦ì‹ ë¶„í•  ìƒí™˜ì˜ ê²½ìš°, ê° ê°œì›” ìˆ˜ì™€ ìƒí™˜ ê¸ˆì•¡ì„ ëª…í™•íˆ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.  
                - ê°ê°ì˜ ê³µì‹ì„ ì´ìš©í•´ ê³„ì‚°í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ê°’ ì¤‘ ì‚¬ìš©ìì˜ ëŒ€ë‹µì— ì–´ë– í•œ ê°’ì´ ë¹ ì ¸ìˆë‹¤ë©´ ê·¸ ê°’ì„ ìš”ì²­í•´ì•¼ í•©ë‹ˆë‹¤. 
                - í•„ìˆ˜ ê°’ì´ ëˆ„ë½ë˜ì—ˆì„ ê²½ìš°  
                    ë§Œì•½ ì œê³µë˜ì§€ ì•Šì€ ê°’ì´ ìˆì„ ê²½ìš°, ê³„ì‚°ì„ ì •í™•íˆ ì§„í–‰í•˜ê¸° ìœ„í•´ í•´ë‹¹ ê°’ì„ ìš”ì²­í•©ë‹ˆë‹¤: ì˜ˆì‹œ: "ìƒí™˜ ê¸°ê°„ì„ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?", "ëŒ€ì¶œ ì›ê¸ˆì„ ì•Œë ¤ì£¼ì„¸ìš”.", "ì—° ì´ììœ¨ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”." 

                ### ë‹µë³€ ###  
                í•„ìˆ˜ ì…ë ¥ ê°’ 
                ì‚¬ìš©ìê°€ ìš”ì²­í•œ ê³„ì‚°ì„ ìœ„í•´ì„œëŠ” ëª‡ ê°€ì§€ ê°’ë“¤ì´ í•„ìš”í•©ë‹ˆë‹¤. ì•„ë˜ì˜ ì •ë³´ë¥¼ ì œê³µí•´ ì£¼ì‹œë©´ ê³„ì‚°ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

                1. ëŒ€ì¶œ ì›ê¸ˆ (P)  
                - ì˜ˆì‹œ: 5ì²œë§Œ ì›, 1ì–µ ì› ë“±

                2. ì—° ì´ììœ¨ (r)  
                - ì˜ˆì‹œ: 3%, 5% ë“±

                3. ìƒí™˜ ê¸°ê°„ (n)  
                - ì˜ˆì‹œ: 5ë…„, 10ë…„ ë“± (ê°œì›” ìˆ˜ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤)

                4. ì²« ë‹¬ ìƒí™˜ ê¸ˆì•¡ (ì²« ë‹¬ì˜ ì›ë¦¬ê¸ˆ ê· ë“± ìƒí™˜ê¸ˆì•¡ì´ë‚˜ ì²´ì¦ì‹ ìƒí™˜ ê¸ˆì•¡ì˜ ì‹œì‘ì )**  
                - ì˜ˆì‹œ: ì²« ë‹¬ì— 50ë§Œ ì›ìœ¼ë¡œ ì‹œì‘ ë“±

                ### ê³„ì‚° ì§„í–‰ ###  
                ë§Œì•½ ì œê³µë˜ì§€ ì•Šì€ ê°’ì´ ìˆì„ ê²½ìš°, ê³„ì‚°ì„ ì •í™•íˆ ì§„í–‰í•˜ê¸° ìœ„í•´ ë°˜ë“œì‹œ í•´ë‹¹ ê°’ì„ ìš”ì²­í•©ë‹ˆë‹¤: ì˜ˆì‹œ: "ìƒí™˜ ê¸°ê°„ì„ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?", "ëŒ€ì¶œ ì›ê¸ˆì„ ì•Œë ¤ì£¼ì„¸ìš”.", "ì—° ì´ììœ¨ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”."
                ëª¨ë“  í•„ìˆ˜ ê°’ì´ ì œê³µë˜ë©´, ê³„ì‚°ì„ ì§„í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  
                ê° ìƒí™˜ ë°©ì‹ì— ë”°ë¼ ê³„ì‚°ì´ ì´ë£¨ì–´ì§€ë©°, ê²°ê³¼ëŠ” ì‚¬ìš©ìì˜ ìš”êµ¬ì— ë§ì¶° ì œê³µí•©ë‹ˆë‹¤.
                ê³„ì‚° ê³¼ì •ì€ ê³„ì‚° ê³µì‹ë§Œ ì œê³µí•˜ë©°, ê³„ì‚° í›„ ê²°ê³¼ ê°’ë§Œ ê°„ë‹¨í•˜ê²Œ ì œê³µí•´ì£¼ì„¸ìš”.
                ì‚¬ìš©ì ì¹œí™”ì ì´ê²Œ í•„ìš”í•˜ë‹¤ë©´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì¸ìš©í•´ì„œ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
            """
        )
    )

    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm, 
        retriever=retriever, 
        chain_type="stuff",
        memory=memory,
        chain_type_kwargs={
            "prompt": custom_prompt,
            "verbose": False
        }
    )

    def custom_run(query):
        nonlocal flag_var
        print("í”Œë˜ê·¸ ì •ë³´:",flag_var)

        retrieved_docs = retriever.get_relevant_documents(query)
        print(f"\nğŸ” ì§ˆë¬¸: {query}")
        print(f"ğŸ“‚ ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(retrieved_docs)}")

        # ì€í–‰ë³„ë¡œ ëŒ€ì¶œ ìƒí’ˆ ì •ë¦¬
        bank_products = {}
        sources = set()

        for doc in retrieved_docs:       
            try:
                bank_name = doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ").split(os.sep)[-2]
            except IndexError:
                bank_name = doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ").split("_")[0]
                flag_var = None
            
            sources.add(doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ"))

            if bank_name not in bank_products:
                bank_products[bank_name] = []

            bank_products[bank_name].append(doc.page_content[:700]) # ìµœëŒ€  700ì ê¹Œì§€ ì €ì¥

        bank_info_text = "**ì€í–‰ë³„ ëŒ€ì¶œ ìƒí’ˆ ì •ë³´:**\n"
        for bank, products in bank_products.items():
            bank_info_text += f"\nğŸ¦ **{bank.upper()}**\n"
            for i, product in enumerate(products, start=1):
                bank_info_text += f"{i}. {product}...\n"

        modified_query = f"{query}\n\n{bank_info_text}"
        print("ì‹¤í–‰ ì¿¼ë¦¬: ", modified_query)
        response = qa_chain.run(modified_query)

        response_text = ""
        if flag_var is not None:
            response_text = f"ğŸ’¡ **AI ë‹µë³€:**\n{response}\n\nğŸ“Œ **ì¶œì²˜:**{', '.join(sources)}"
        else:
            response_text = f"ğŸ’¡ **AI ë‹µë³€:**\n{response}"

        return response_text

    return custom_run

def generate_feedback(history, user_feedback, qa_chain):
    conversation_log = "\n".join([f"ì‚¬ìš©ì: {q}\nAI: {a}" for q, a in history])
    evaluation_prompt = f"""
        ë‹¹ì‹ ì€ AI ëŒ€í™” í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ëŒ€í™”ë¥¼ í‰ê°€í•˜ì„¸ìš”.

        ### ëŒ€í™” ë‚´ì—­ ###
        {conversation_log}

        ### ì‚¬ìš©ì í”¼ë“œë°± ###
        '{user_feedback}' (ğŸ‘ ë§Œì¡± / ğŸ¤” ë³´í†µ / ğŸ‘ ê°œì„  í•„ìš”)

        ### í‰ê°€ ê¸°ì¤€ ###
        - ì •ë³´ì˜ ëª…í™•ì„±(1~5)
        - ë‹µë³€ì˜ ëª…í™•ì„±(1~5)
        - ì‚¬ìš©ì ì¹œí™”ì„±(1~5)
        - ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„

        ì‚¬ìš©ì í”¼ë“œë°±ì„ ê³ ë ¤í•˜ì—¬ AIì˜ ê°•ì ê³¼ ê°œì„ ì ì„ ë¶„ì„í•˜ê³ , ë³´ì™„í•  ì ì„ ì œì•ˆí•˜ì„¸ìš”.
    """

    return qa_chain(evaluation_prompt)

def main():
    st.markdown(
        "<h2 style='text-align: center;'>ğŸ’¬ ì€í–‰ ì „ì„¸ìê¸ˆëŒ€ì¶œ ë° ì£¼íƒë‹´ë³´ëŒ€ì¶œ Q&A ì±—ë´‡</h2>",
        unsafe_allow_html=True
    )
    st.write("ì€í–‰ ì „ì„¸ìê¸ˆëŒ€ì¶œ ë° ì£¼íƒë‹´ë³´ëŒ€ì¶œ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!")

    # ChromaDB ì´ˆê¸°í™”
    if not os.path.exists(CHROMA_PATH):
        st.info("ë¬¸ì„œ DBë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...")
        db = create_chroma_db()
    else:
        embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
        db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embeddings)

    qa_chain = get_qa_chain_with_memory(db, "user")

    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
    
    if st.button("ì§ˆë¬¸í•˜ê¸°") and (user_input not in ["ëŒ€í™” ì¢…ë£Œ"]):
        with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            response = qa_chain(user_input)  # ê³¼ê±° ëŒ€í™” ë°˜ì˜ë¨
            st.success(response)

            if "history" not in st.session_state:
                st.session_state.history = []
            st.session_state.history.insert(0, (user_input, response))

    if user_input in ["ëŒ€í™” ì¢…ë£Œ"]:
        st.success("ğŸ˜Š ë„ì›€ì´ ë˜ì—ˆë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤! ì¶”ê°€ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”.")
        st.write("ğŸ‘‰ í˜¹ì‹œ ì´ë²ˆ ë‹µë³€ì´ ë§Œì¡±ìŠ¤ëŸ¬ì› ë‚˜ìš”? ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ í”¼ë“œë°±ì„ ë‚¨ê²¨ì£¼ì„¸ìš”!")

        user_feedback = st.radio("ë‹µë³€ì´ ë§Œì¡±ìŠ¤ëŸ¬ì› ë‚˜ìš”?", ("ğŸ‘ ë§Œì¡±", "ğŸ¤” ë³´í†µ", "ğŸ‘ ê°œì„  í•„ìš”"), index=None)
        if user_feedback:
            if "feedback_processed" not in st.session_state or not st.session_state.feedback_processed:
                with st.spinner("ëŒ€í™” í‰ê°€ ì¤‘..."):
                    feedback = generate_feedback(st.session_state.history, user_feedback, qa_chain)
                    st.session_state.feedback_message = feedback

                    st.session_state.feedback_processed = True

                    # if st.button("ğŸ”„"): // ì¤€ë¹„ ì•ˆëŒ
                    #     st.session_state.feedback_processed=False
                    #     st.experimental_rerun()
            if "feedback_message" in st.session_state and st.session_state.feedback_message:
                st.write("ğŸ§ AI ìì²´ í‰ê°€ ê²°ê³¼:")
                st.write(f"âœ… í”¼ë“œë°±ì´ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤: {st.session_state.feedback_message}")
                    
        if "history" in st.session_state and st.session_state.history:
            conversation_log = "\n".join([f"ì‚¬ìš©ì: {q}\nAI: {a}" for q, a in st.session_state.history])
                    
            today = datetime.today().strftime('%Y.%m.%d')
            download_filename = f"{today}_conversation_history.txt"
            st.download_button(
                label="ëŒ€í™” ë‚´ìš© ë‹¤ìš´ë¡œë“œí•˜ê¸°",
                data=conversation_log,
                file_name=download_filename,
                mime="text/plain"
            )


    # ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    if "history" in st.session_state and st.session_state.history:
        st.write("### ğŸ“œ ì´ì „ ëŒ€í™” ê¸°ë¡")
        for question, answer in st.session_state.history:
            st.write(f"**â“:** {question}")
            st.write(f"**ğŸ‘€:** {answer}")
            st.write("---")

if __name__ == "__main__":
    main()
