import os
import streamlit as st
from langchain.chains import RetrievalQA
from langchain.memory import ConversationBufferMemory
from langchain_openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain_chroma import Chroma
from langchain.text_splitter import CharacterTextSplitter
from langchain.document_loaders import PyPDFLoader


# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
OPENAI_API_KEY = '[API KEY ì…ë ¥]'
DATA_PATH = "./data"
CHROMA_PATH = "./chroma_db"

def load_documents():
    documents = []
    for root, _, files in os.walk(DATA_PATH):
        for file in files:
            if file.endswith('.pdf'):
                pdf_path = os.path.join(root, file)
                print(f"ğŸ“„ PDF ë¡œë“œ ì¤‘: {pdf_path}")

                loader = PyPDFLoader(pdf_path)
                docs = loader.load()

                print(f"ğŸ”¹ {file}ì—ì„œ {len(docs)}ê°œì˜ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
                documents.extend(docs)
    
    return documents

def create_chroma_db():
    documents = load_documents()
    print(f"ğŸ“š ì´ {len(documents)}ê°œì˜ ë¬¸ì„œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    docs = text_splitter.split_documents(documents)
    print(f"ğŸ” ë¬¸ì„œ ë¶„í•  ì™„ë£Œ: ì´ {len(docs)}ê°œì˜ ì²­í¬ ìƒì„±ë¨")
    
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY) # ì‚¬ìš© ì„ë² ë”© ëª¨ë¸: text-embedding-ada-002
    db = Chroma.from_documents(docs, embeddings, persist_directory=CHROMA_PATH)
    print("âœ… ChromaDB ì €ì¥ ì™„ë£Œ!")
    return db

def get_qa_chain_with_memory(db):
    retriever = db.as_retriever(search_kwargs={"k": 10})
    llm = ChatOpenAI(model_name="gpt-4o", openai_api_key=OPENAI_API_KEY, temperature=0.5)
    
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm, 
        retriever=retriever, 
        chain_type="stuff",
        memory=memory
    )

    def custom_run(query):
        retrieved_docs = retriever.get_relevant_documents(query)
        print(f"\nğŸ” ì§ˆë¬¸: {query}")
        print(f"ğŸ“‚ ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(retrieved_docs)}")

        bank_products = {}
        sources = set()

        for doc in retrieved_docs: 
            bank_name = doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ").split(os.sep)[-2]
            sources.add(doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ"))

            if bank_name not in bank_products:
                bank_products[bank_name] = []

            bank_products[bank_name].append(doc.page_content[:700]) # ìµœëŒ€  700ì ê¹Œì§€ ì €ì¥

        bank_info_text = "**ì€í–‰ë³„ ëŒ€ì¶œ ìƒí’ˆ ì •ë³´:**\n"
        for bank, products in bank_products.items():
            bank_info_text += f"\nğŸ¦ **{bank.upper()}**\n"
            for i, product in enumerate(products, start=1):
                bank_info_text += f"{i}. {product}...\n"

        modified_query = f"{query}\n\n{bank_info_text}"
        print(modified_query)
        response = qa_chain.run(modified_query)

        response_text = f"ğŸ’¡ **AI ë‹µë³€:**\n{response}\n\nğŸ“Œ **ì¶œì²˜:** {', '.join(sources)}"
        return response_text

    return custom_run

def main():
    st.title("ğŸ’¬ì€í–‰ ì „ì„¸ìê¸ˆëŒ€ì¶œ Q&A ì±—ë´‡")
    st.write("ì€í–‰ ì „ì„¸ìê¸ˆëŒ€ì¶œ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!")

    # ChromaDB ì´ˆê¸°í™”
    if not os.path.exists(CHROMA_PATH):
        st.info("ë¬¸ì„œ DBë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...")
        db = create_chroma_db()
    else:
        embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
        db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embeddings)

    qa_chain = get_qa_chain_with_memory(db)

    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
    
    if st.button("ì§ˆë¬¸í•˜ê¸°") and user_input:
        with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            response = qa_chain(user_input)  # ê³¼ê±° ëŒ€í™” ë°˜ì˜ë¨
            st.success("ğŸ“ ë‹µë³€:")
            st.write(response)  # PDF ì¶œì²˜ í¬í•¨

            if "history" not in st.session_state:
                st.session_state.history = []
            st.session_state.history.append((user_input, response))

    # ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    if "history" in st.session_state and st.session_state.history:
        st.write("### ğŸ“œ ì´ì „ ëŒ€í™” ê¸°ë¡")
        for question, answer in st.session_state.history:
            st.write(f"**Q:** {question}")
            st.write(f"**A:** {answer}")
            st.write("---")

if __name__ == "__main__":
    main()
